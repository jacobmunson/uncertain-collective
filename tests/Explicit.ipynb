{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill as pickle\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import BASE_COLORS\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from uncertain.utils.data import Data\n",
    "from uncertain.utils.training import train\n",
    "from uncertain.utils.evaluation import test_recommendations, uncertainty_distributions\n",
    "\n",
    "from uncertain.explicit import MF, CPMF, OrdRec\n",
    "from uncertain.extras import Ensemble, Resample, UncertainWrapper, UserHeuristic, ItemHeuristic\n",
    "\n",
    "data = pd.read_csv('data/data.csv')\n",
    "data.columns = ['user', 'item', 'score', 'timestamps']\n",
    "ML = Data(data, implicit=False, batch_size=2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExplicitMF (FunkSVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = 1000\n",
    "for wd in [1e-5, 5e-6, 1e-6]:\n",
    "    model = MF(ML.n_user, ML.n_item, embedding_dim=10, lr=1e-3, weight_decay=wd)\n",
    "    this_loss = train(model, ML)\n",
    "    if this_loss < best_loss:\n",
    "        best_loss = this_loss\n",
    "        with open('fitted/baseline.pth', 'wb') as f:\n",
    "            pickle.dump(model, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model]\n",
    "for _ in range(2):\n",
    "    models.append(MF(ML.n_user, ML.n_item, embedding_dim=10, lr=1e-3, weight_decay=5e-06))\n",
    "    train(models[-1], ML)\n",
    "\n",
    "model_ = Ensemble(models)\n",
    "with open('fitted/ensemble.pkl', 'wb') as f:\n",
    "    pickle.dump(model_, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "og = deepcopy(ML.train)\n",
    "for _ in range(3):\n",
    "    ML.train = og[np.random.choice(len(og), int(0.8*len(og)), replace=False), :]\n",
    "    models.append(MF(ML.n_user, ML.n_item, embedding_dim=10, lr=1e-3, weight_decay=model.weight_decay))\n",
    "    train(models[-1], ML)\n",
    "model_ = Resample(model, models)\n",
    "with open('fitted/resample.pkl', 'wb') as f:\n",
    "    pickle.dump(model_, f, pickle.HIGHEST_PROTOCOL)\n",
    "ML.train = og"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zhu et. al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.empty(len(ML.train))\n",
    "og = deepcopy(ML)\n",
    "for train_idx, test_idx in KFold(n_splits=2, shuffle=True).split(ML.train):\n",
    "    test = og.train[test_idx]\n",
    "    ML.train = og.train[train_idx]\n",
    "    model_ = MF(ML.n_user, ML.n_item, embedding_dim=10, lr=1e-3, weight_decay=model.weight_decay)\n",
    "    train(model_, ML)\n",
    "    errors[test_idx] = np.abs(model_.predict(torch.tensor(test[:, 0]).long(), torch.tensor(test[:, 1]).long()) - test[:, 2])\n",
    "ML.train = deepcopy(og.train)\n",
    "ML.train[:, 2] = errors\n",
    "ML.val[:, 2] = np.abs(model.predict(torch.tensor(ML.val[:, 0]).long(), torch.tensor(ML.val[:, 1]).long()) - ML.val[:, 2])\n",
    "model_ = MF(ML.n_user, ML.n_item, embedding_dim=10, lr=1e-3, weight_decay=model.weight_decay)\n",
    "train(model_, ML)\n",
    "ML = og\n",
    "with open('fitted/zhu.pth', 'wb') as f:\n",
    "    pickle.dump(model_, f, pickle.HIGHEST_PROTOCOL)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = 1000\n",
    "grid = [1e-5, 5e-6, 1e-6]\n",
    "pairs = [(wd0, wd1) for wd0 in grid for wd1 in grid]\n",
    "for wd0, wd1 in pairs:\n",
    "    model = CPMF(ML.n_user, ML.n_item, embedding_dim=10, lr=1e-3, weight_decay_MF=wd0, weight_decay_gammas=wd1)\n",
    "    this_loss = train(model, ML)\n",
    "    if this_loss < best_loss:\n",
    "        best_loss = this_loss\n",
    "        with open('fitted/cpmf.pth', 'wb') as f:\n",
    "            pickle.dump(model, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OrdRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML.to_ordinal()\n",
    "best_loss = 1000\n",
    "grid = [1e-5, 5e-6, 1e-6]\n",
    "pairs = [(wd0, wd1) for wd0 in grid for wd1 in grid]\n",
    "for wd0, wd1 in pairs:\n",
    "    model = OrdRec(ML.n_user, ML.n_item, ML.score_labels, embedding_dim=10, lr=1e-3, weight_decay_MF=wd0, weight_decay_step=wd1)\n",
    "    this_loss = train(model, ML)\n",
    "    if this_loss < best_loss:\n",
    "        best_loss = this_loss\n",
    "        with open('fitted/ordrec.pth', 'wb') as f:\n",
    "            pickle.dump(model, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "# Baseline\n",
    "with open('fitted/baseline.pth', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "results['MF'] = test_recommendations(model, ML, max_k=10)\n",
    "\n",
    "# Heuristics\n",
    "user_support = np.bincount(ML.train_val.user)\n",
    "item = ML.train_val.groupby('item').agg({'user': 'size', 'score': 'var'})\n",
    "empty = np.where(~pd.Series(np.arange(ML.n_item)).isin(item.index))[0]\n",
    "empty = pd.DataFrame(np.full((len(empty), 2), float('NaN')), index=empty, columns=['user', 'score'])\n",
    "item = item.append(empty).sort_index().fillna(0).to_numpy()\n",
    "results['User support'] = test_recommendations(UserHeuristic(base_MF=model, uncertainty=-user_support), ML, max_k=10)\n",
    "results['Item support'] = test_recommendations(ItemHeuristic(base_MF=model, uncertainty=-item[:, 0]), ML, max_k=10)\n",
    "results['Item variance'] = test_recommendations(ItemHeuristic(base_MF=model, uncertainty=item[:, 1]), ML, max_k=10)\n",
    "\n",
    "# Ensemble\n",
    "with open('fitted/ensemble.pkl', 'rb') as f:\n",
    "    model_ = pickle.load(f)\n",
    "results['Ensemble'] = test_recommendations(model_, ML, max_k=10)\n",
    "\n",
    "# Resample\n",
    "with open('fitted/resample.pkl', 'rb') as f:\n",
    "    model_ = pickle.load(f)\n",
    "results['Resample'] = test_recommendations(model_, ML, max_k=10)\n",
    "\n",
    "# Zhu\n",
    "with open('fitted/zhu.pth', 'rb') as f:\n",
    "    model_ = pickle.load(f)\n",
    "results['MF-CV'] = test_recommendations(UncertainWrapper(model, model_), ML, max_k=10)\n",
    "\n",
    "# CPMF\n",
    "with open('fitted/cpmf.pth', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "results['MF'] = test_recommendations(model, ML, max_k=10)\n",
    "model.weight_decay_MF, model.weight_decay_gammas, results['MF'], model.recommend(0)\n",
    "\n",
    "# OrdRec\n",
    "model.weight_decay, results['MF']\n",
    "with open('fitted/ordrec.pth', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "results['MF'] = test_recommendations(model, ML, max_k=10)\n",
    "model.weight_decay_MF, model.weight_decay_step, results['MF'], model.recommend(0)\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(results, orient='Index')\n",
    "ratings = results_df[['RMSE', 'RPI', 'Classification']]\n",
    "print(ratings)\n",
    "colors = [c for c in list(BASE_COLORS)]\n",
    "keys = results_df.index.to_list()\n",
    "colors = {keys[i]:colors[i] for i in range(len(keys))}\n",
    "\n",
    "f, ax = plt.subplots(ncols=2, figsize=(18, 5))\n",
    "for key in keys:\n",
    "    ax[0].plot(np.arange(1, 11), results_df['Novelty'][key],\n",
    "               '-', color=colors[key], label=key, linewidth=3, alpha=0.6)\n",
    "    ax[1].plot(np.arange(2, 11), results_df['Diversity'][key],\n",
    "               '-', color=colors[key], label=key, linewidth=3, alpha=0.6)\n",
    "ax[0].set_xticks(np.arange(1, 11))\n",
    "ax[0].set_xlabel('K', fontsize=20)\n",
    "ax[0].set_ylabel('Expected surprise@K', fontsize=20)\n",
    "ax[0].legend(ncol=2, fontsize=15)\n",
    "ax[1].set_xticks(np.arange(2, 11))\n",
    "ax[1].set_xlabel('K', fontsize=20)\n",
    "ax[1].set_ylabel('Diversity@K', fontsize=20)\n",
    "ax[1].legend(ncol=2, fontsize=15)\n",
    "f.tight_layout()\n",
    "\n",
    "f, ax = plt.subplots(ncols=3, figsize=(18, 5), sharex=True)\n",
    "for key in keys:\n",
    "    ax[0].plot(np.arange(1, 11), results_df['Precision'][key],\n",
    "               '-', color=colors[key], label=key, linewidth=3, alpha=0.6)\n",
    "    ax[1].plot(np.arange(1, 11), results_df['Recall'][key],\n",
    "               '-', color=colors[key], label=key, linewidth=3, alpha=0.6)\n",
    "    ax[2].plot(np.arange(1, 11), results_df['NDCG'][key],\n",
    "               '-', color=colors[key], label=key, linewidth=3, alpha=0.6)\n",
    "ax[0].set_xticks(np.arange(1, 11))\n",
    "ax[0].set_xlabel('K', fontsize=20)\n",
    "ax[0].set_ylabel('Precision@K', fontsize=20)\n",
    "ax[0].legend(ncol=2, fontsize=15)\n",
    "ax[1].set_xlabel('K', fontsize=20)\n",
    "ax[1].set_ylabel('Recall@K', fontsize=20)\n",
    "ax[1].legend(ncol=2, fontsize=15)\n",
    "ax[2].set_xlabel('K', fontsize=20)\n",
    "ax[2].set_ylabel('NDCG@K', fontsize=20)\n",
    "ax[2].legend(ncol=2, fontsize=15)\n",
    "f.tight_layout()\n",
    "\n",
    "f, ax = plt.subplots(ncols=2, figsize=(18, 5))\n",
    "keys = ['CPMF', 'OrdRec']\n",
    "for key in keys:\n",
    "    ax[0].plot(np.arange(1, 21), results_df['Quantile RMSE'][key],\n",
    "            '-', color=colors[key], label=key, linewidth=3, alpha=0.6)\n",
    "    ax[1].plot(np.arange(1, 11), results_df['RRI'][key],\n",
    "            '-', color=colors[key], label=key, linewidth=3, alpha=0.6)\n",
    "ax[0].set_xticks(np.arange(1, 21))\n",
    "ax[0].set_xticklabels([round(elem, 2) for elem in np.linspace(start=0.05, stop=1, num=20).tolist()])\n",
    "ax[0].set_xlabel('Uncertainty quantile', fontsize=20)\n",
    "ax[0].set_ylabel('RMSE', fontsize=20)\n",
    "ax[0].legend(ncol=2, fontsize=20)\n",
    "ax[1].set_xlabel('K', fontsize=20)\n",
    "ax[1].set_ylabel('RRI@K', fontsize=20)\n",
    "ax[1].legend(ncol=2, fontsize=20)\n",
    "f.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
